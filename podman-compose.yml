version: "3.8"

services:
  whisper-server:
    image: localhost/whisper-cuda:2025-12-21
    container_name: whisper-server
    entrypoint: ["/home/b08x/LLMOS/whisper.cpp/build/bin/whisper-server"]
    command:
      - "-m"
      - "/home/b08x/LLMOS/whisper.cpp/models/ggml-large-v3-turbo-q5_0.bin"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8080"
      - "-t"
      - "8" # number of threads
      - "--convert" # enable audio format conversion with ffmpeg
    ports:
      - "8080:8080"
    volumes:
      - /var/home/b08x:/home/b08x:ro # Mount home directory read-only
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
